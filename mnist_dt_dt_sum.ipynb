{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_dt_dt_sum.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYeQiQ7PtRb/ZCQJQHSPEy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joyjeni/ComputerVision/blob/main/mnist_dt_dt_sum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NbIOp6mE4_-"
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9Y63HIsa9SL"
      },
      "source": [
        "### Importing Relevant Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmAkGaZVa4ra"
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from random import randrange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTEzAwQFa4uq"
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize((28,28)),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5,), (0.5,))\n",
        "                               ])\n",
        "training_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "print(\"Total Training Data:\",len(training_dataset))\n",
        "validation_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "print(\"Total Validation Data:\",len(validation_dataset))\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejnaz6Fr_jUj"
      },
      "source": [
        "\n",
        "def im_convert(tensor):\n",
        "  image = tensor.clone().detach().numpy()\n",
        "  image = image.transpose(1, 2, 0)\n",
        "  image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n",
        "  image = image.clip(0, 1)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R0-KxAk_GWn"
      },
      "source": [
        "def view_classify(img, ps):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq__gYR3a4xy"
      },
      "source": [
        "\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "\n",
        "for idx in np.arange(20):\n",
        "  ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
        "  plt.imshow(im_convert(images[idx]))\n",
        "  ax.set_title([labels[idx].item()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0J4KxeEa40o"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, D_in, H1, H2, D_out):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(D_in, H1)\n",
        "        self.linear2 = nn.Linear(H1, H2)\n",
        "        self.linear3 = nn.Linear(H2, D_out)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(x))  \n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-i-zo0w-Xsn"
      },
      "source": [
        "\n",
        "model = Classifier(784, 125, 65, 10)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBlpsWSOCfTj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z3ppBkwDBv6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM8hNRf6DCs5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKg8fxveDBzf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPQpvus5-XwG"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3Dk1EaX-Xzp"
      },
      "source": [
        "epochs = 15\n",
        "running_loss_history = []\n",
        "running_corrects_history = []\n",
        "val_running_loss_history = []\n",
        "val_running_corrects_history = []\n",
        "\n",
        "for e in range(epochs):\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0.0\n",
        "  val_running_loss = 0.0\n",
        "  val_running_corrects = 0.0\n",
        "  \n",
        "  for inputs, labels in training_loader:\n",
        "    inputs = inputs.view(inputs.shape[0], -1)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    running_loss += loss.item()\n",
        "    running_corrects += torch.sum(preds == labels.data)  \n",
        "\n",
        "  else:\n",
        "    with torch.no_grad():\n",
        "      for val_inputs, val_labels in validation_loader:\n",
        "        val_inputs = val_inputs.view(val_inputs.shape[0], -1)\n",
        "        val_outputs = model(val_inputs)\n",
        "        val_loss = criterion(val_outputs, val_labels)\n",
        "        \n",
        "        _, val_preds = torch.max(val_outputs, 1)\n",
        "        val_running_loss += val_loss.item()\n",
        "        val_running_corrects += torch.sum(val_preds == val_labels.data)\n",
        "      \n",
        "    epoch_loss = running_loss/len(training_loader)\n",
        "    epoch_acc = running_corrects.float()/ len(training_loader)\n",
        "    running_loss_history.append(epoch_loss)\n",
        "    running_corrects_history.append(epoch_acc)\n",
        "    \n",
        "    val_epoch_loss = val_running_loss/len(validation_loader)\n",
        "    val_epoch_acc = val_running_corrects.float()/ len(validation_loader)\n",
        "    val_running_loss_history.append(val_epoch_loss)\n",
        "    val_running_corrects_history.append(val_epoch_acc)\n",
        "    print('epoch :', (e+1))\n",
        "    print('training loss: {:.4f}, acc {:.4f} '.format(epoch_loss, epoch_acc.item()))\n",
        "    print('validation loss: {:.4f}, validation acc {:.4f} '.format(val_epoch_loss, val_epoch_acc.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjl-wRWL-j8G"
      },
      "source": [
        "plt.plot(running_loss_history, label='training loss')\n",
        "plt.plot(val_running_loss_history, label='validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q7jq0WE-j_j"
      },
      "source": [
        "plt.plot(running_corrects_history, label='training accuracy')\n",
        "plt.plot(val_running_corrects_history, label='validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYNz9ZkAFome"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIDMKfH4G8_w"
      },
      "source": [
        "#from random import randrange\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE5oVI4jIwOg"
      },
      "source": [
        "### Add two numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17DN5q_pG9DE"
      },
      "source": [
        "random_num=randrange(10)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for num in preds:\n",
        "\n",
        "    X = np.array([preds[num],random_num])\n",
        "    y=np.array(sum(X))\n",
        "\n",
        "    N = len(preds)  # number of samples\n",
        "    D = 2  # input dimension\n",
        "    C = 1  # output dimension\n",
        "\n",
        "    X = torch.rand(N, D).to(device)  # (N, D)\n",
        "    y = torch.sum(X, axis=-1).reshape(-1, C)  # (N, C)\n",
        "\n",
        "    lr = 1e-2  # Learning rate\n",
        "\n",
        "    model = torch.nn.Sequential(torch.nn.Linear(D, C))  # model\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = torch.nn.MSELoss()  # loss function\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # optimizer\n",
        "\n",
        "    for epoch in range(1000):\n",
        "        y_pred = model(X)  # forward step\n",
        "        loss = criterion(y_pred, y)  # compute loss\n",
        "        loss.backward()  # backprop (compute gradients)\n",
        "        optimizer.step()  # update weights (gradient descent step)\n",
        "        optimizer.zero_grad()  # reset gradients\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == y)\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "            print(f\"[EPOCH]: {epoch}, [LOSS]: {loss.item():.6f}\")\n",
        "\n",
        "\n",
        "\n",
        "         \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVh7rUqebXWQ"
      },
      "source": [
        "plt.plot(running_loss_history, label='training loss')\n",
        "plt.plot(val_running_loss_history, label='validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJVw5pJhbXhe"
      },
      "source": [
        "plt.plot(running_corrects_history, label='training accuracy')\n",
        "plt.plot(val_running_corrects_history, label='validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzMZhNFvJgBt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBPyDM6XJiY0"
      },
      "source": [
        "### Get MNIST prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muayyaPuJlwx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vh0HFrpOV3M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47A5B__vOWyx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}