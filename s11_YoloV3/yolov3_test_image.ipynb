{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolov3_test_image.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnBaJONSQuvR"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTCJezchQ4qb"
      },
      "source": [
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive/EVA6/yolov3/YOLO-3-OpenCV/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEYlf7WBQ4ts"
      },
      "source": [
        "% cd $path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQMP9aXARcfD"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JU7hAjASL-Z"
      },
      "source": [
        "image_BGR = cv2.imread('./images/jenisha.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGN9k6c40Gc-"
      },
      "source": [
        "image_BGR.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCVlU1xnWaCT"
      },
      "source": [
        "#cv2.namedWindow('Original Image', cv2.WINDOW_NORMAL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrQTPfY4WaFY"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(image_BGR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqyEcgMASSsl"
      },
      "source": [
        " # Check point\n",
        " # Showing image shape\n",
        " print('Image shape:', image_BGR.shape)  # tuple of (511, 767, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_hBkz2oXEDf"
      },
      "source": [
        "# Getting spatial dimension of input image\n",
        "h, w = image_BGR.shape[:2]  # Slicing from tuple only first two elements\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKVzeCnuXEGi"
      },
      "source": [
        "# # Check point\n",
        "# # Showing height an width of image\n",
        "print('Image height={0} and width={1}'.format(h, w))  # 511 767"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQmEap0KXMKR"
      },
      "source": [
        "\"\"\"\n",
        "Start of:\n",
        "Getting blob from input image\n",
        "\"\"\"\n",
        "\n",
        "blob = cv2.dnn.blobFromImage(image_BGR, 1 / 255.0, (416, 416),\n",
        "                             swapRB=True, crop=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdp6K5DpXUyM"
      },
      "source": [
        "with open('./yolo-coco-data/coco.names') as f:\n",
        "    # Getting labels reading every line\n",
        "    # and putting them into the list\n",
        "    labels = [line.strip() for line in f]\n",
        "\n",
        "\n",
        "# # Check point\n",
        "# print('List with labels names:')\n",
        "# print(labels)\n",
        "\n",
        "# Loading trained YOLO v3 Objects Detector\n",
        "# with the help of 'dnn' library from OpenCV\n",
        "# Pay attention! If you're using Windows, yours paths might look like:\n",
        "# r'yolo-coco-data\\yolov3.cfg'\n",
        "# r'yolo-coco-data\\yolov3.weights'\n",
        "# or:\n",
        "# 'yolo-coco-data\\\\yolov3.cfg'\n",
        "# 'yolo-coco-data\\\\yolov3.weights'\n",
        "network = cv2.dnn.readNetFromDarknet('./yolo-coco-data/yolov3.cfg',\n",
        "                                     './yolo-coco-data/yolov3.weights')\n",
        "\n",
        "# Getting list with names of all layers from YOLO v3 network\n",
        "layers_names_all = network.getLayerNames()\n",
        "\n",
        "# # Check point\n",
        "# print()\n",
        "# print(layers_names_all)\n",
        "\n",
        "# Getting only output layers' names that we need from YOLO v3 algorithm\n",
        "# with function that returns indexes of layers with unconnected outputs\n",
        "layers_names_output = \\\n",
        "    [layers_names_all[i[0] - 1] for i in network.getUnconnectedOutLayers()]\n",
        "\n",
        "# # Check point\n",
        "# print()\n",
        "# print(layers_names_output)  # ['yolo_82', 'yolo_94', 'yolo_106']\n",
        "\n",
        "# Setting minimum probability to eliminate weak predictions\n",
        "probability_minimum = 0.5\n",
        "\n",
        "# Setting threshold for filtering weak bounding boxes\n",
        "# with non-maximum suppression\n",
        "threshold = 0.3\n",
        "\n",
        "# Generating colours for representing every detected object\n",
        "# with function randint(low, high=None, size=None, dtype='l')\n",
        "colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n",
        "\n",
        "# # Check point\n",
        "# print()\n",
        "# print(type(colours))  # <class 'numpy.ndarray'>\n",
        "# print(colours.shape)  # (80, 3)\n",
        "# print(colours[0])  # [172  10 127]\n",
        "\n",
        "\"\"\"\n",
        "End of:\n",
        "Loading YOLO v3 network\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Start of:\n",
        "Implementing Forward pass\n",
        "\"\"\"\n",
        "\n",
        "# Implementing forward pass with our blob and only through output layers\n",
        "# Calculating at the same time, needed time for forward pass\n",
        "network.setInput(blob)  # setting blob as input to the network\n",
        "start = time.time()\n",
        "output_from_network = network.forward(layers_names_output)\n",
        "end = time.time()\n",
        "\n",
        "# Showing spent time for forward pass\n",
        "print('Objects Detection took {:.5f} seconds'.format(end - start))\n",
        "\n",
        "\"\"\"\n",
        "End of:\n",
        "Implementing Forward pass\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Start of:\n",
        "Getting bounding boxes\n",
        "\"\"\"\n",
        "\n",
        "# Preparing lists for detected bounding boxes,\n",
        "# obtained confidences and class's number\n",
        "bounding_boxes = []\n",
        "confidences = []\n",
        "class_numbers = []\n",
        "\n",
        "\n",
        "# Going through all output layers after feed forward pass\n",
        "for result in output_from_network:\n",
        "    # Going through all detections from current output layer\n",
        "    for detected_objects in result:\n",
        "        # Getting 80 classes' probabilities for current detected object\n",
        "        scores = detected_objects[5:]\n",
        "        # Getting index of the class with the maximum value of probability\n",
        "        class_current = np.argmax(scores)\n",
        "        # Getting value of probability for defined class\n",
        "        confidence_current = scores[class_current]\n",
        "\n",
        "        # # Check point\n",
        "        # # Every 'detected_objects' numpy array has first 4 numbers with\n",
        "        # # bounding box coordinates and rest 80 with probabilities for every class\n",
        "        # print(detected_objects.shape)  # (85,)\n",
        "\n",
        "        # Eliminating weak predictions with minimum probability\n",
        "        if confidence_current > probability_minimum:\n",
        "            # Scaling bounding box coordinates to the initial image size\n",
        "            # YOLO data format keeps coordinates for center of bounding box\n",
        "            # and its current width and height\n",
        "            # That is why we can just multiply them elementwise\n",
        "            # to the width and height\n",
        "            # of the original image and in this way get coordinates for center\n",
        "            # of bounding box, its width and height for original image\n",
        "            box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
        "\n",
        "            # Now, from YOLO data format, we can get top left corner coordinates\n",
        "            # that are x_min and y_min\n",
        "            x_center, y_center, box_width, box_height = box_current\n",
        "            x_min = int(x_center - (box_width / 2))\n",
        "            y_min = int(y_center - (box_height / 2))\n",
        "\n",
        "            # Adding results into prepared lists\n",
        "            bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
        "            confidences.append(float(confidence_current))\n",
        "            class_numbers.append(class_current)\n",
        "\n",
        "\"\"\"\n",
        "End of:\n",
        "Getting bounding boxes\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Start of:\n",
        "Non-maximum suppression\n",
        "\"\"\"\n",
        "\n",
        "# Implementing non-maximum suppression of given bounding boxes\n",
        "# With this technique we exclude some of bounding boxes if their\n",
        "# corresponding confidences are low or there is another\n",
        "# bounding box for this region with higher confidence\n",
        "\n",
        "# It is needed to make sure that data type of the boxes is 'int'\n",
        "# and data type of the confidences is 'float'\n",
        "# https://github.com/opencv/opencv/issues/12789\n",
        "results = cv2.dnn.NMSBoxes(bounding_boxes, confidences,\n",
        "                           probability_minimum, threshold)\n",
        "\n",
        "\"\"\"\n",
        "End of:\n",
        "Non-maximum suppression\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fqriq5WXfy1"
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "Start of:\n",
        "Drawing bounding boxes and labels\n",
        "\"\"\"\n",
        "\n",
        "# Defining counter for detected objects\n",
        "counter = 1\n",
        "\n",
        "# Checking if there is at least one detected object after non-maximum suppression\n",
        "if len(results) > 0:\n",
        "    # Going through indexes of results\n",
        "    for i in results.flatten():\n",
        "        # Showing labels of the detected objects\n",
        "        print('Object {0}: {1}'.format(counter, labels[int(class_numbers[i])]))\n",
        "\n",
        "        # Incrementing counter\n",
        "        counter += 1\n",
        "\n",
        "        # Getting current bounding box coordinates,\n",
        "        # its width and height\n",
        "        x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
        "        box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
        "\n",
        "        # Preparing colour for current bounding box\n",
        "        # and converting from numpy array to list\n",
        "        colour_box_current = colours[class_numbers[i]].tolist()\n",
        "\n",
        "        # # # Check point\n",
        "        # print(type(colour_box_current))  # <class 'list'>\n",
        "        # print(colour_box_current)  # [172 , 10, 127]\n",
        "\n",
        "        # Drawing bounding box on the original image\n",
        "        cv2.rectangle(image_BGR, (x_min, y_min),\n",
        "                      (x_min + box_width, y_min + box_height),\n",
        "                      colour_box_current, 2)\n",
        "\n",
        "        # Preparing text with label and confidence for current bounding box\n",
        "        text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])],\n",
        "                                               confidences[i])\n",
        "\n",
        "        # Putting text with label and confidence on the original image\n",
        "        cv2.putText(image_BGR, text_box_current, (x_min, y_min - 5),\n",
        "                    cv2.FONT_HERSHEY_COMPLEX, 0.7, colour_box_current, 2)\n",
        "\n",
        "\n",
        "# Comparing how many objects where before non-maximum suppression\n",
        "# and left after\n",
        "print()\n",
        "print('Total objects been detected:', len(bounding_boxes))\n",
        "print('Number of objects left after non-maximum suppression:', counter - 1)\n",
        "\n",
        "\"\"\"\n",
        "End of:\n",
        "Drawing bounding boxes and labels\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj1ngsQRYNOS"
      },
      "source": [
        "\n",
        "# Showing Original Image with Detected Objects\n",
        "# Giving name to the window with Original Image\n",
        "# And specifying that window is resizable\n",
        "#cv2.namedWindow('Detections', cv2.WINDOW_NORMAL)\n",
        "# Pay attention! 'cv2.imshow' takes images in BGR format\n",
        "cv2_imshow(image_BGR)\n",
        "cv2.imwrite('./images/jenisha_car.jpeg',image_BGR)\n",
        "\n",
        "# Waiting for any key being pressed\n",
        "#cv2.waitKey(0)\n",
        "# Destroying opened window with name 'Detections'\n",
        "#cv2.destroyWindow('Detections')\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Some comments\n",
        "\n",
        "With OpenCV function 'cv2.dnn.blobFromImage' we get 4-dimensional\n",
        "so called 'blob' from input image after mean subtraction,\n",
        "normalizing, and RB channels swapping. Resulted shape has:\n",
        " - number of images\n",
        " - number of channels\n",
        " - width\n",
        " - height\n",
        "E.G.: blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size, mean, swapRB=True)\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}