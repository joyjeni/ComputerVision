{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "advanced_convolutions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCa86viWMbo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d05e26-22f5-47ad-8a61-afd5dbed6c9f"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ3mo9eOMdSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3107e7d0-4a08-4686-d821-54b7f8e52e96"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej5-Kf6iNVks"
      },
      "source": [
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive/EVA6/s7_depthwise_cifar10/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtUDDqAtNVpX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d82123-cd6f-49a6-cfb7-5986bc76be3c"
      },
      "source": [
        "% cd $path"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/EVA6/s7_depthwise_cifar10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ66Gkd-Nv7O"
      },
      "source": [
        "WORKING_DIR=\"ComputerVision\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e4BSxnFR6xJ"
      },
      "source": [
        "!if [ -d \"$WORKING_DIR\" ]; then rm -Rf $WORKING_DIR; fi"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "affAINtdMGrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bedd8fb-ca00-4d50-af55-4e86c2bc163f"
      },
      "source": [
        "!git clone https://github.com/joyjeni/ComputerVision/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ComputerVision'...\n",
            "remote: Enumerating objects: 292, done.\u001b[K\n",
            "remote: Counting objects: 100% (292/292), done.\u001b[K\n",
            "remote: Compressing objects: 100% (223/223), done.\u001b[K\n",
            "remote: Total 292 (delta 115), reused 111 (delta 38), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (292/292), 776.00 KiB | 4.46 MiB/s, done.\n",
            "Resolving deltas: 100% (115/115), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kl9y8JCPCNg"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgPuwYX0MdVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ebee63a-1852-47f2-ca80-be7cafe2f481"
      },
      "source": [
        "%cd ComputerVision/s7_cifar10_Depthwise_Separable_Conv/Pybeam"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/EVA6/s7_depthwise_cifar10/ComputerVision/s7_cifar10_Depthwise_Separable_Conv/Pybeam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGU5R7EfQE7k"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJTL6oQUP32X"
      },
      "source": [
        "#### Run the CIFAR10 Model for 50 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dP4c9V1P3JP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9815582f-b50f-4c4e-b5ce-60d9d183d9ed"
      },
      "source": [
        "!python main.py --config=experiments/cifar10_config.yml --device=0"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-19 00:26:01,383 - beam.__main__ ] INFO: Training: {'name': 'CIFAR10_MyNet', 'save_dir': 'saved/', 'seed': 1, 'target_device': 0, 'arch': {'type': 'CIFAR10Model', 'args': {}}, 'augmentation': {'type': 'CIFAR10Transforms', 'args': {}}, 'data_loader': {'type': 'CIFAR10DataLoader', 'args': {'batch_size': 64, 'data_dir': 'data/', 'nworkers': 4, 'shuffle': True}}, 'loss': 'nll_loss', 'optimizer': {'type': 'SGD', 'args': {'lr': 0.008, 'momentum': 0.95}}, 'training': {'epochs': 50}}\n",
            "[ 2021-06-19 00:26:01,386 - beam.__main__ ] INFO: Building: beam.model.model.CIFAR10Model\n",
            "[ 2021-06-19 00:26:01,420 - beam.__main__ ] INFO: Using device 0 of available devices [0]\n",
            "[ 2021-06-19 00:26:04,601 - beam.__main__ ] INFO: Building: torch.optim.SGD\n",
            "[ 2021-06-19 00:26:04,601 - beam.__main__ ] INFO: Building: beam.data_loader.augmentation.CIFAR10Transforms\n",
            "[ 2021-06-19 00:26:04,601 - beam.__main__ ] INFO: Building: beam.data_loader.data_loaders.CIFAR10DataLoader\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n",
            "170499072it [00:03, 43164608.10it/s]                   \n",
            "Extracting data/cifar-10-python.tar.gz to data/\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "[ 2021-06-19 00:26:13,701 - beam.__main__ ] INFO: Getting loss function handle\n",
            "[ 2021-06-19 00:26:13,701 - beam.__main__ ] INFO: Initializing trainer\n",
            "[ 2021-06-19 00:26:13,701 - beam.beam.base.base_trainer ] INFO: Starting training ...\n",
            "[ 2021-06-19 00:26:13,701 - beam.beam.base.base_trainer ] INFO: Training the model for 50 epochs\n",
            "Training Epoch: 1\n",
            "epoch=1 loss=1.7532749176 batch_id=781: 100% 782/782 [00:14<00:00, 54.49it/s]\n",
            "Test set: Accuracy: 42.53\n",
            "Training Epoch: 2\n",
            "epoch=2 loss=0.9653954506 batch_id=781: 100% 782/782 [00:12<00:00, 60.24it/s]\n",
            "Test set: Accuracy: 51.46\n",
            "Training Epoch: 3\n",
            "epoch=3 loss=1.3891534805 batch_id=781: 100% 782/782 [00:13<00:00, 59.90it/s]\n",
            "Test set: Accuracy: 56.4\n",
            "Training Epoch: 4\n",
            "epoch=4 loss=1.5307861567 batch_id=781: 100% 782/782 [00:12<00:00, 60.45it/s]\n",
            "Test set: Accuracy: 63.48\n",
            "Training Epoch: 5\n",
            "epoch=5 loss=1.4569220543 batch_id=781: 100% 782/782 [00:12<00:00, 60.48it/s]\n",
            "Test set: Accuracy: 66.03\n",
            "Training Epoch: 6\n",
            "epoch=6 loss=1.2787325382 batch_id=781: 100% 782/782 [00:12<00:00, 60.96it/s]\n",
            "Test set: Accuracy: 67.49\n",
            "Training Epoch: 7\n",
            "epoch=7 loss=1.1498714685 batch_id=781: 100% 782/782 [00:12<00:00, 61.14it/s]\n",
            "Test set: Accuracy: 67.31\n",
            "Training Epoch: 8\n",
            "epoch=8 loss=1.0640559196 batch_id=781: 100% 782/782 [00:12<00:00, 60.60it/s]\n",
            "Test set: Accuracy: 72.34\n",
            "Training Epoch: 9\n",
            "epoch=9 loss=1.0954281092 batch_id=781: 100% 782/782 [00:12<00:00, 60.58it/s]\n",
            "Test set: Accuracy: 71.67\n",
            "Training Epoch: 10\n",
            "epoch=10 loss=0.6216870546 batch_id=781: 100% 782/782 [00:12<00:00, 60.64it/s]\n",
            "Test set: Accuracy: 74.5\n",
            "Training Epoch: 11\n",
            "epoch=11 loss=1.0566953421 batch_id=781: 100% 782/782 [00:12<00:00, 60.85it/s]\n",
            "Test set: Accuracy: 74.72\n",
            "Training Epoch: 12\n",
            "epoch=12 loss=0.8162484169 batch_id=781: 100% 782/782 [00:13<00:00, 60.04it/s]\n",
            "Test set: Accuracy: 75.71\n",
            "Training Epoch: 13\n",
            "epoch=13 loss=1.1085811853 batch_id=781: 100% 782/782 [00:12<00:00, 61.18it/s]\n",
            "Test set: Accuracy: 76.59\n",
            "Training Epoch: 14\n",
            "epoch=14 loss=0.9231085777 batch_id=781: 100% 782/782 [00:12<00:00, 60.53it/s]\n",
            "Test set: Accuracy: 76.04\n",
            "Training Epoch: 15\n",
            "epoch=15 loss=1.4738956690 batch_id=781: 100% 782/782 [00:12<00:00, 60.22it/s]\n",
            "Test set: Accuracy: 77.4\n",
            "Training Epoch: 16\n",
            "epoch=16 loss=1.1640284061 batch_id=781: 100% 782/782 [00:12<00:00, 60.56it/s]\n",
            "Test set: Accuracy: 76.29\n",
            "Training Epoch: 17\n",
            "epoch=17 loss=0.4672740996 batch_id=781: 100% 782/782 [00:12<00:00, 61.21it/s]\n",
            "Test set: Accuracy: 78.33\n",
            "Training Epoch: 18\n",
            "epoch=18 loss=0.8295024633 batch_id=781: 100% 782/782 [00:12<00:00, 61.34it/s]\n",
            "Test set: Accuracy: 78.23\n",
            "Training Epoch: 19\n",
            "epoch=19 loss=0.7233512402 batch_id=781: 100% 782/782 [00:13<00:00, 60.04it/s]\n",
            "Test set: Accuracy: 79.02\n",
            "Training Epoch: 20\n",
            "epoch=20 loss=0.8804616332 batch_id=781: 100% 782/782 [00:12<00:00, 60.29it/s]\n",
            "Test set: Accuracy: 79.91\n",
            "Training Epoch: 21\n",
            "epoch=21 loss=0.7269604802 batch_id=781: 100% 782/782 [00:13<00:00, 60.05it/s]\n",
            "Test set: Accuracy: 78.9\n",
            "Training Epoch: 22\n",
            "epoch=22 loss=0.4811615646 batch_id=781: 100% 782/782 [00:12<00:00, 60.93it/s]\n",
            "Test set: Accuracy: 80.3\n",
            "Training Epoch: 23\n",
            "epoch=23 loss=1.2490507364 batch_id=781: 100% 782/782 [00:12<00:00, 60.36it/s]\n",
            "Test set: Accuracy: 79.56\n",
            "Training Epoch: 24\n",
            "epoch=24 loss=0.5847241282 batch_id=781: 100% 782/782 [00:12<00:00, 60.40it/s]\n",
            "Test set: Accuracy: 80.33\n",
            "Training Epoch: 25\n",
            "epoch=25 loss=0.8940169811 batch_id=781: 100% 782/782 [00:12<00:00, 60.87it/s]\n",
            "Test set: Accuracy: 80.8\n",
            "Training Epoch: 26\n",
            "epoch=26 loss=0.8133534193 batch_id=781: 100% 782/782 [00:12<00:00, 61.27it/s]\n",
            "Test set: Accuracy: 80.72\n",
            "Training Epoch: 27\n",
            "epoch=27 loss=0.2833986878 batch_id=781: 100% 782/782 [00:12<00:00, 61.23it/s]\n",
            "Test set: Accuracy: 80.96\n",
            "Training Epoch: 28\n",
            "epoch=28 loss=0.7975014448 batch_id=781: 100% 782/782 [00:12<00:00, 60.70it/s]\n",
            "Test set: Accuracy: 81.41\n",
            "Training Epoch: 29\n",
            "epoch=29 loss=0.6136043072 batch_id=781: 100% 782/782 [00:12<00:00, 60.85it/s]\n",
            "Test set: Accuracy: 80.95\n",
            "Training Epoch: 30\n",
            "epoch=30 loss=0.2705523670 batch_id=781: 100% 782/782 [00:13<00:00, 59.95it/s]\n",
            "Test set: Accuracy: 81.02\n",
            "Training Epoch: 31\n",
            "epoch=31 loss=0.4921842813 batch_id=781: 100% 782/782 [00:12<00:00, 60.44it/s]\n",
            "Test set: Accuracy: 81.15\n",
            "Training Epoch: 32\n",
            "epoch=32 loss=1.0790590048 batch_id=781: 100% 782/782 [00:13<00:00, 60.12it/s]\n",
            "Test set: Accuracy: 81.92\n",
            "Training Epoch: 33\n",
            "epoch=33 loss=0.8463363051 batch_id=781: 100% 782/782 [00:12<00:00, 60.79it/s]\n",
            "Test set: Accuracy: 81.56\n",
            "Training Epoch: 34\n",
            "epoch=34 loss=0.3702622652 batch_id=781: 100% 782/782 [00:13<00:00, 58.71it/s]\n",
            "Test set: Accuracy: 81.95\n",
            "Training Epoch: 35\n",
            "epoch=35 loss=0.1561110169 batch_id=781: 100% 782/782 [00:13<00:00, 58.23it/s]\n",
            "Test set: Accuracy: 81.95\n",
            "Training Epoch: 36\n",
            "epoch=36 loss=1.0109243393 batch_id=781: 100% 782/782 [00:13<00:00, 58.57it/s]\n",
            "Test set: Accuracy: 81.83\n",
            "Training Epoch: 37\n",
            "epoch=37 loss=1.0518331528 batch_id=781: 100% 782/782 [00:13<00:00, 59.79it/s]\n",
            "Test set: Accuracy: 82.19\n",
            "Training Epoch: 38\n",
            "epoch=38 loss=0.3563365340 batch_id=781: 100% 782/782 [00:12<00:00, 60.42it/s]\n",
            "Test set: Accuracy: 82.24\n",
            "Training Epoch: 39\n",
            "epoch=39 loss=0.8138939738 batch_id=781: 100% 782/782 [00:13<00:00, 60.02it/s]\n",
            "Test set: Accuracy: 82.76\n",
            "Training Epoch: 40\n",
            "epoch=40 loss=0.6433296800 batch_id=781: 100% 782/782 [00:12<00:00, 60.52it/s]\n",
            "Test set: Accuracy: 83.17\n",
            "Training Epoch: 41\n",
            "epoch=41 loss=0.8094690442 batch_id=781: 100% 782/782 [00:13<00:00, 60.09it/s]\n",
            "Test set: Accuracy: 82.8\n",
            "Training Epoch: 42\n",
            "epoch=42 loss=0.5045867562 batch_id=781: 100% 782/782 [00:12<00:00, 60.60it/s]\n",
            "Test set: Accuracy: 83.2\n",
            "Training Epoch: 43\n",
            "epoch=43 loss=0.6130573750 batch_id=781: 100% 782/782 [00:12<00:00, 60.19it/s]\n",
            "Test set: Accuracy: 82.92\n",
            "Training Epoch: 44\n",
            "epoch=44 loss=0.3246805966 batch_id=781: 100% 782/782 [00:12<00:00, 60.23it/s]\n",
            "Test set: Accuracy: 83.7\n",
            "Training Epoch: 45\n",
            "epoch=45 loss=0.3403141499 batch_id=781: 100% 782/782 [00:12<00:00, 60.29it/s]\n",
            "Test set: Accuracy: 83.39\n",
            "Training Epoch: 46\n",
            "epoch=46 loss=0.5161500573 batch_id=781: 100% 782/782 [00:12<00:00, 60.29it/s]\n",
            "Test set: Accuracy: 83.5\n",
            "Training Epoch: 47\n",
            "epoch=47 loss=0.4621923268 batch_id=781: 100% 782/782 [00:12<00:00, 60.18it/s]\n",
            "Test set: Accuracy: 83.73\n",
            "Training Epoch: 48\n",
            "epoch=48 loss=0.6966356039 batch_id=781: 100% 782/782 [00:12<00:00, 60.24it/s]\n",
            "Test set: Accuracy: 83.63\n",
            "Training Epoch: 49\n",
            "epoch=49 loss=0.5023806095 batch_id=781: 100% 782/782 [00:13<00:00, 59.95it/s]\n",
            "Test set: Accuracy: 83.81\n",
            "Training Epoch: 50\n",
            "epoch=50 loss=0.7732542753 batch_id=781: 100% 782/782 [00:12<00:00, 60.35it/s]\n",
            "Test set: Accuracy: 83.78\n",
            "[ 2021-06-19 00:38:39,726 - beam.__main__ ] INFO: Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E99FUEepcPsR"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P96nT9u9PJxr"
      },
      "source": [
        "class CIFAR10Model(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout_value=0.25):\n",
        "\n",
        "        self.dropout_value = dropout_value  # dropout value\n",
        "\n",
        "        super(CIFAR10Model, self).__init__()\n",
        "\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32,\n",
        "                      kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )  # output_size = 32\n",
        "\n",
        "        # CONVOLUTION BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64,\n",
        "                      kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )  # output_size = 32\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=32,\n",
        "                      kernel_size=(1, 1), padding=0, bias=False,stride=2),\n",
        "        )  # output_size = 32\n",
        "      \n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        # DEPTHWISE CONVOLUTION AND POINTWISE CONVOLUTION\n",
        "        self.depthwise1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64,\n",
        "                      kernel_size=(3, 3), padding=0, groups=32, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )  # output_size = 16\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128,\n",
        "                      kernel_size=(1, 1), padding=0, bias=False,stride=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )  # output_size = 16\n",
        "\n",
        "       \n",
        "        # CONVOLUTION BLOCK 3\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128,\n",
        "                      kernel_size=(3, 3), padding=4, dilation=2, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )  # output_size = 11\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128,\n",
        "                      kernel_size=(3, 3), padding=1, bias=False,stride=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )  # output_size = 11\n",
        "\n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=5)\n",
        "        )  # output_size = 1\n",
        "\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128,\n",
        "                      kernel_size=(1, 1), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        )\n",
        "\n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=10,\n",
        "                      kernel_size=(1, 1), padding=0, bias=False),\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(self.dropout_value)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "\n",
        "        x = self.depthwise1(x)\n",
        "        x = self.convblock4(x)\n",
        "\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "\n",
        "        x = self.gap(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.convblock8(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_UTFuo3PKjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8efcce86-42e9-48db-b790-3903c7b5a36c"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = CIFAR10Model().to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "           Dropout-4           [-1, 32, 32, 32]               0\n",
            "            Conv2d-5           [-1, 64, 32, 32]          18,432\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "              ReLU-7           [-1, 64, 32, 32]               0\n",
            "           Dropout-8           [-1, 64, 32, 32]               0\n",
            "            Conv2d-9           [-1, 32, 16, 16]           2,048\n",
            "           Conv2d-10           [-1, 64, 14, 14]             576\n",
            "      BatchNorm2d-11           [-1, 64, 14, 14]             128\n",
            "             ReLU-12           [-1, 64, 14, 14]               0\n",
            "          Dropout-13           [-1, 64, 14, 14]               0\n",
            "           Conv2d-14            [-1, 128, 7, 7]           8,192\n",
            "      BatchNorm2d-15            [-1, 128, 7, 7]             256\n",
            "             ReLU-16            [-1, 128, 7, 7]               0\n",
            "          Dropout-17            [-1, 128, 7, 7]               0\n",
            "           Conv2d-18          [-1, 128, 11, 11]         147,456\n",
            "      BatchNorm2d-19          [-1, 128, 11, 11]             256\n",
            "             ReLU-20          [-1, 128, 11, 11]               0\n",
            "          Dropout-21          [-1, 128, 11, 11]               0\n",
            "           Conv2d-22            [-1, 128, 6, 6]         147,456\n",
            "      BatchNorm2d-23            [-1, 128, 6, 6]             256\n",
            "             ReLU-24            [-1, 128, 6, 6]               0\n",
            "          Dropout-25            [-1, 128, 6, 6]               0\n",
            "        AvgPool2d-26            [-1, 128, 1, 1]               0\n",
            "           Conv2d-27            [-1, 128, 1, 1]          16,384\n",
            "             ReLU-28            [-1, 128, 1, 1]               0\n",
            "      BatchNorm2d-29            [-1, 128, 1, 1]             256\n",
            "          Dropout-30            [-1, 128, 1, 1]               0\n",
            "           Conv2d-31             [-1, 10, 1, 1]           1,280\n",
            "================================================================\n",
            "Total params: 344,032\n",
            "Trainable params: 344,032\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.25\n",
            "Params size (MB): 1.31\n",
            "Estimated Total Size (MB): 5.58\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}